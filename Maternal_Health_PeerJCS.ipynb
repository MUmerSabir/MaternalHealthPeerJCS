{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0Ko2ZrWsTuS8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vO7a1MGNTuS9"
      },
      "outputs": [],
      "source": [
        "#Reading MaternalHealth dataset\n",
        "data = pd.read_csv('MaternalHealth.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading MaternalHealth dataset first give rows\n",
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UegQiqMRUOKT",
        "outputId": "e88ca135-44d3-4053-81a2-0c0df7c43f2d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  SystolicBP  DiastolicBP    BS  BodyTemp  HeartRate  RiskLevel\n",
              "0   25         130           80  15.0      98.0         86  high risk\n",
              "1   35         140           90  13.0      98.0         70  high risk\n",
              "2   29          90           70   8.0     100.0         80  high risk\n",
              "3   30         140           85   7.0      98.0         70  high risk\n",
              "4   35         120           60   6.1      98.0         76   low risk"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37dc6556-f2d8-4cb7-a195-ad71d09f8ef5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>SystolicBP</th>\n",
              "      <th>DiastolicBP</th>\n",
              "      <th>BS</th>\n",
              "      <th>BodyTemp</th>\n",
              "      <th>HeartRate</th>\n",
              "      <th>RiskLevel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>130</td>\n",
              "      <td>80</td>\n",
              "      <td>15.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>86</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>13.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>90</td>\n",
              "      <td>70</td>\n",
              "      <td>8.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>80</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>140</td>\n",
              "      <td>85</td>\n",
              "      <td>7.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35</td>\n",
              "      <td>120</td>\n",
              "      <td>60</td>\n",
              "      <td>6.1</td>\n",
              "      <td>98.0</td>\n",
              "      <td>76</td>\n",
              "      <td>low risk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37dc6556-f2d8-4cb7-a195-ad71d09f8ef5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37dc6556-f2d8-4cb7-a195-ad71d09f8ef5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37dc6556-f2d8-4cb7-a195-ad71d09f8ef5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking MaternalHealth dataset missing values\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moun3JljURwP",
        "outputId": "6dd671a7-b78f-466b-daad-d4692225d87e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age            0\n",
              "SystolicBP     0\n",
              "DiastolicBP    0\n",
              "BS             0\n",
              "BodyTemp       0\n",
              "HeartRate      0\n",
              "RiskLevel      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#information of MaternalHealth dataset\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rc_fD_cEUaJP",
        "outputId": "7fa7a6e1-3065-427f-d917-01b81b117bfd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1014 entries, 0 to 1013\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Age          1014 non-null   int64  \n",
            " 1   SystolicBP   1014 non-null   int64  \n",
            " 2   DiastolicBP  1014 non-null   int64  \n",
            " 3   BS           1014 non-null   float64\n",
            " 4   BodyTemp     1014 non-null   float64\n",
            " 5   HeartRate    1014 non-null   int64  \n",
            " 6   RiskLevel    1014 non-null   object \n",
            "dtypes: float64(2), int64(4), object(1)\n",
            "memory usage: 55.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting PCA Features\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "X = data.drop('species',axis=1)\n",
        "Y = data['species']\n",
        "\n",
        "PCA_TR = PCA(n_components=3)\n",
        "X_train = PCA_TR.fit_transform(X)\n",
        "PCA_TR.explained_variance_ratio_"
      ],
      "metadata": {
        "id": "-p-VZnOmUhMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_TR.components_"
      ],
      "metadata": {
        "id": "wUw0J0aaefkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(PCA_TR.components_,columns=X.columns,index = ['PC-1','PC-2','PC-3'])"
      ],
      "metadata": {
        "id": "FS3gfq-Fef0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Kfold results\n",
        "from sklearn.model_selection import StratifiedKFold,cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "LRM = LogisticRegression()\n",
        "DTC = DecisionTreeClassifier()\n",
        "RFC = RandomForestClassifier()\n",
        "KNC = KNeighborsClassifier()\n",
        "NBC = GaussianNB()\n",
        "\n",
        "SKF = StratifiedKFold(n_splits = 10, shuffle =True, random_state=10)\n",
        "\n",
        "print(f'LogisticRegression : {round(cross_val_score(LRM,X_train,Y,cv=SKF,scoring=\"accuracy\").mean()*100,2)}%')\n",
        "print(f'DecisionTreeClassifier : {round(cross_val_score(DTC,X_train,Y,cv=SKF,scoring=\"accuracy\").mean()*100,2)}%')\n",
        "print(f'RandomForestClassifier : {round(cross_val_score(RFC,X_train,Y,cv=SKF,scoring=\"accuracy\").mean()*100,2)}%')\n",
        "print(f'KNeighborsClassifier : {round(cross_val_score(KNC,X_train,Y,cv=SKF,scoring=\"accuracy\").mean()*100,2)}%')\n",
        "print(f'GaussianNB : {round(cross_val_score(NBC,X_train,Y,cv=SKF,scoring=\"accuracy\").mean()*100,2)}%')"
      ],
      "metadata": {
        "id": "xQ64GVl5eiOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "y=data[\"RiskLevel\"]\n",
        "x=data.drop([\"RiskLevel\"], axis=1)\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = preprocessing.LabelEncoder()"
      ],
      "metadata": {
        "id": "Rez4ZaZCUBph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all PCA features models\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
        "print(\"RF\")\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=52)\n",
        "pred = rfc.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,pred))\n",
        "print(\"ADA\")\n",
        "xgb = AdaBoostClassifier(n_estimators=100, random_state=52)\n",
        "xgb_pred = xgb.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,xgb_pred))\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "dt = DecisionTreeClassifier(random_state=50)\n",
        "print(\"Decision Tree Classifier Result\")\n",
        "DecisionTree=dt.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,DecisionTree))\n",
        "from sklearn.svm import SVC\n",
        "print(\"SVC\")\n",
        "svm = SVC(kernel='linear', C=2.0, random_state=52)\n",
        "svm.fit(X_train,y_train)\n",
        "y_pred=svm.predict(X_test)\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(\"ETC\")\n",
        "b = ExtraTreesClassifier(n_estimators=100, random_state=52)\n",
        "b_pred = b.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,b_pred))\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "print(\"MultinomialNB NB\")\n",
        "gnb = MultinomialNB()\n",
        "gnb_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,gnb_pred))\n",
        "# Fitting XGBoost to the training data\n",
        "XGBClassifier = xgb.XGBClassifier()\n",
        "XGBoost=my_model.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,XGBoost))\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr=LogisticRegression()\n",
        "print(\"Logistic Regression Result\")\n",
        "logisticRegresion=lr.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,logisticRegresion))\n",
        "\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "print(\"Stochastic Gradient Classifier\")\n",
        "clf = SGDClassifier(max_iter=1100, tol=1e-3)\n",
        "calibrated_clf = CalibratedClassifierCV(clf, cv=5, method='isotonic')\n",
        "predSGD=calibrated_clf.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,predSGD))\n",
        "\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "#from sklearn.linear_model import SGDClassifier\n",
        "print(\"Voting Classifier XGB+RF+ETC\")\n",
        "clf1 = xgb.XGBClassifier()\n",
        "clf2 = RandomForestClassifier(n_estimators=100, random_state=52)\n",
        "clf3 = ExtraTreesClassifier(n_estimators=100, random_state=52)\n",
        "eclf1 = VotingClassifier(estimators=[\n",
        "        ('xgb', clf1), ('rf', clf2), ('etc', clf3)],voting='hard')\n",
        "predictionVC=eclf1.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,predictionVC))"
      ],
      "metadata": {
        "id": "E7KV7ZMeUnqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uarhCGQRTuTB"
      },
      "outputs": [],
      "source": [
        "# Splitting dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AI0hNb7JTuTC"
      },
      "outputs": [],
      "source": [
        "len(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x0Fj4gPTuTC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUi2ODiHTuTC"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt=DecisionTreeClassifier(max_depth=50)\n",
        "dtPre=dt.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,dtPre))\n",
        "print(classification_report(y_test,dtPre))\n",
        "print(confusion_matrix(y_test,dtPre))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Jb4nxBmTuTC"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "print(\"ADA\")\n",
        "xgb = AdaBoostClassifier(n_estimators=200, random_state=5)\n",
        "xgb_pred = xgb.fit(X_train, y_train).predict(X_test)\n",
        "print(classification_report(y_test,xgb_pred))\n",
        "print(confusion_matrix(y_test,xgb_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-a1rWTY0TuTD"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "print(\"SVC\")\n",
        "svm = SVC(kernel='linear', C=1.0, random_state=500)\n",
        "svm.fit(X_train,y_train)\n",
        "y_pred=svm.predict(X_test)\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UXfYIECTuTD"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier(n_estimators=200, random_state=5, max_depth=20)\n",
        "rfc.fit(X_train, y_train)\n",
        "# calculate accuracy of class predictions\n",
        "y_pred_class = rfc.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_class))\n",
        "print(confusion_matrix(y_test,y_pred_class))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ8LafJjTuTD"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "print(\"ETC\")\n",
        "b = ExtraTreesClassifier(n_estimators=200, random_state=5, max_depth=20)\n",
        "b_pred = b.fit(X_train, y_train).predict(X_test)\n",
        "print(classification_report(y_test,b_pred))\n",
        "print(confusion_matrix(y_test,b_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM-A4_DpTuTD"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "# 2. instantiate a logistic regression model\n",
        "logreg = LogisticRegression(random_state=1000, solver='liblinear',multi_class='ovr',C=3.0)\n",
        "# 3. train the model using X_train_dtm\n",
        "x=logreg.fit(X_train, y_train)\n",
        "# 4. make class predictions for X_test_dtm\n",
        "y_pred_class = logreg.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_class))\n",
        "print(confusion_matrix(y_test,y_pred_class))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18ErM3lhTuTD"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "r3=SGDClassifier(max_iter=1000, tol=1e-3,loss='perceptron')\n",
        "x=r3.fit(X_train, y_train)\n",
        "\n",
        "y_pred_class = r3.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_class))\n",
        "print(confusion_matrix(y_test,y_pred_class))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "r1 = LogisticRegression(random_state=1000, solver='liblinear',multi_class='ovr',C=3.0)\n",
        "r2 = SVC(kernel='linear', C=1.0, random_state=500,probability=True)\n",
        "r3 = SGDClassifier(max_iter=1000, tol=1e-3,loss='perceptron')\n",
        "er = VotingClassifier([('lr', r1),('svc', r2),('sgdc', r3)],voting=\"hard\")\n",
        "\n",
        "x=er.fit(X_train, y_train)\n",
        "\n",
        "y_pred_class = er.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_class))\n",
        "print(confusion_matrix(y_test,y_pred_class))\n"
      ],
      "metadata": {
        "id": "gxx6rovUVeFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67l00LbOTuTI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1K5DmQKTuTI"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from keras.layers import Dropout , Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.initializers import glorot_uniform\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras.backend as K\n",
        "from sklearn.utils import shuffle\n",
        "# importing all necessary libraries to run the code\n",
        "import re,string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras_metrics\n",
        "import tensorflow.keras\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation,Embedding\n",
        "# using the variable sw to hold all stopwords that are in English\n",
        "sw = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YC3rewo2TuTI"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33TZS18pTuTI"
      },
      "outputs": [],
      "source": [
        "X_train_res=df.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xynwf3OBTuTK"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt=DecisionTreeClassifier(max_depth=50)\n",
        "dtPre=dt.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,dtPre))\n",
        "print(classification_report(y_test,dtPre))\n",
        "print(confusion_matrix(y_test,dtPre))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier(n_estimators=200, random_state=5, max_depth=20)\n",
        "rfc.fit(X_train, y_train)\n",
        "# calculate accuracy of class predictions\n",
        "y_pred_class = rfc.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_class))\n",
        "print(confusion_matrix(y_test,y_pred_class))"
      ],
      "metadata": {
        "id": "-lSEdExeWCUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoak1VaNTuTL"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "print(\"ETC\")\n",
        "b = ExtraTreesClassifier(n_estimators=300, random_state=5, max_depth=20)\n",
        "b_pred = b.fit(X_train, y_train).predict(X_test)\n",
        "print(classification_report(y_test,b_pred))\n",
        "print(confusion_matrix(y_test,b_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "print(\"ADA\")\n",
        "xgb = AdaBoostClassifier(n_estimators=100, random_state=5)\n",
        "xgb_pred = xgb.fit(X_train, y_train).predict(X_test)\n",
        "print(classification_report(y_test,xgb_pred))\n",
        "print(confusion_matrix(y_test,xgb_pred))"
      ],
      "metadata": {
        "id": "8KWF2xnZWF2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gljP_C-pTuTP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "r1 = LogisticRegression(random_state=1000, solver='saga',multi_class='ovr',C=2.0)\n",
        "r2 = SVC(kernel='linear', C=1.0, random_state=2, probability=True)\n",
        "r3=SGDClassifier(loss='perceptron')\n",
        "er = VotingClassifier([('svc', r2),('lr', r1),('sgdc', r3)],voting=\"hard\")\n",
        "\n",
        "x=er.fit(X_train, y_train)\n",
        "\n",
        "y_pred_class = er.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_class))\n",
        "print(confusion_matrix(y_test,y_pred_class))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su6CFAgQTuTP",
        "outputId": "7223400f-25bd-45f5-ad0c-a813d4af2305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81        26\n",
            "           1       0.86      0.86      0.86        35\n",
            "\n",
            "    accuracy                           0.84        61\n",
            "   macro avg       0.83      0.83      0.83        61\n",
            "weighted avg       0.84      0.84      0.84        61\n",
            "\n",
            "[[21  5]\n",
            " [ 5 30]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "# 2. instantiate a logistic regression model\n",
        "logreg = LogisticRegression(random_state=1000, solver='saga',multi_class='ovr',C=2.0)\n",
        "# 3. train the model using X_train_dtm\n",
        "x=logreg.fit(X_train, y_train)\n",
        "# 4. make class predictions for X_test_dtm\n",
        "y_pred_class = logreg.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_class))\n",
        "print(confusion_matrix(y_test,y_pred_class))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE_rAXkxTuTP",
        "outputId": "f778c097-b27a-4860-f9c6-5b49efca96c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVC\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.85      0.81        26\n",
            "           1       0.88      0.83      0.85        35\n",
            "\n",
            "    accuracy                           0.84        61\n",
            "   macro avg       0.83      0.84      0.83        61\n",
            "weighted avg       0.84      0.84      0.84        61\n",
            "\n",
            "[[22  4]\n",
            " [ 6 29]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "print(\"SVC\")\n",
        "svm = SVC(kernel='sigmoid', C=1.0, random_state=2)\n",
        "svm.fit(X_train,y_train)\n",
        "y_pred=svm.predict(X_test)\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqtEXi9OTuTP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zli8U53bTuTP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PV1eqwNTuTP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhUh_XrqTuTQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tidG7D_TuTQ"
      },
      "outputs": [],
      "source": [
        "#PCA feature data\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
        "print(\"RF\")\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=52)\n",
        "pred = rfc.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,pred))\n",
        "print(\"ADA\")\n",
        "xgb = AdaBoostClassifier(n_estimators=100, random_state=52)\n",
        "xgb_pred = xgb.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,xgb_pred))\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "dt = DecisionTreeClassifier(random_state=50)\n",
        "print(\"Decision Tree Classifier Result\")\n",
        "DecisionTree=dt.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,DecisionTree))\n",
        "from sklearn.svm import SVC\n",
        "print(\"SVC\")\n",
        "svm = SVC(kernel='linear', C=2.0, random_state=52)\n",
        "svm.fit(X_train,y_train)\n",
        "y_pred=svm.predict(X_test)\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(\"ETC\")\n",
        "b = ExtraTreesClassifier(n_estimators=100, random_state=52)\n",
        "b_pred = b.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,b_pred))\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "print(\"MultinomialNB NB\")\n",
        "gnb = MultinomialNB()\n",
        "gnb_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,gnb_pred))\n",
        "# Fitting XGBoost to the training data\n",
        "XGBClassifier = xgb.XGBClassifier()\n",
        "XGBoost=my_model.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,XGBoost))\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr=LogisticRegression()\n",
        "print(\"Logistic Regression Result\")\n",
        "logisticRegresion=lr.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,logisticRegresion))\n",
        "\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "print(\"Stochastic Gradient Classifier\")\n",
        "clf = SGDClassifier(max_iter=1100, tol=1e-3)\n",
        "calibrated_clf = CalibratedClassifierCV(clf, cv=5, method='isotonic')\n",
        "predSGD=calibrated_clf.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,predSGD))\n",
        "\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "#from sklearn.linear_model import SGDClassifier\n",
        "print(\"Voting Classifier XGB+RF+ETC\")\n",
        "clf1 = xgb.XGBClassifier()\n",
        "clf2 = RandomForestClassifier(n_estimators=100, random_state=52)\n",
        "clf3 = ExtraTreesClassifier(n_estimators=100, random_state=52)\n",
        "eclf1 = VotingClassifier(estimators=[\n",
        "        ('xgb', clf1), ('rf', clf2), ('etc', clf3)],voting='hard')\n",
        "predictionVC=eclf1.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,predictionVC))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVzM9pEoTuTQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FyOVatoTuTQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAWrAQKsTuTQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WM0_ES5TuTQ"
      },
      "outputs": [],
      "source": [
        "#PCA features data\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
        "print(\"RF\")\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=52)\n",
        "pred = rfc.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,pred))\n",
        "print(\"ADA\")\n",
        "xgb = AdaBoostClassifier(n_estimators=100, random_state=52)\n",
        "xgb_pred = xgb.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,xgb_pred))\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "dt = DecisionTreeClassifier(random_state=50)\n",
        "print(\"Decision Tree Classifier Result\")\n",
        "DecisionTree=dt.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,DecisionTree))\n",
        "from sklearn.svm import SVC\n",
        "print(\"SVC\")\n",
        "svm = SVC(kernel='linear', C=2.0, random_state=52)\n",
        "svm.fit(X_train,y_train)\n",
        "y_pred=svm.predict(X_test)\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(\"ETC\")\n",
        "b = ExtraTreesClassifier(n_estimators=100, random_state=52)\n",
        "b_pred = b.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,b_pred))\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "print(\"MultinomialNB NB\")\n",
        "gnb = MultinomialNB()\n",
        "gnb_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,gnb_pred))\n",
        "# Fitting XGBoost to the training data\n",
        "XGBClassifier = xgb.XGBClassifier()\n",
        "XGBoost=my_model.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,XGBoost))\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr=LogisticRegression()\n",
        "print(\"Logistic Regression Result\")\n",
        "logisticRegresion=lr.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,logisticRegresion))\n",
        "\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "print(\"Stochastic Gradient Classifier\")\n",
        "clf = SGDClassifier(max_iter=1100, tol=1e-3)\n",
        "calibrated_clf = CalibratedClassifierCV(clf, cv=5, method='isotonic')\n",
        "predSGD=calibrated_clf.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,predSGD))\n",
        "\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "#from sklearn.linear_model import SGDClassifier\n",
        "print(\"Voting Classifier XGB+RF+ETC\")\n",
        "clf1 = xgb.XGBClassifier()\n",
        "clf2 = RandomForestClassifier(n_estimators=100, random_state=52)\n",
        "clf3 = ExtraTreesClassifier(n_estimators=100, random_state=52)\n",
        "eclf1 = VotingClassifier(estimators=[\n",
        "        ('xgb', clf1), ('rf', clf2), ('etc', clf3)],voting='hard')\n",
        "predictionVC=eclf1.fit(X_train, y_train).predict(X_test)\n",
        "print(accuracy_score(y_test,predictionVC))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5_f0knITuTQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rweU3A9fTuTQ"
      },
      "outputs": [],
      "source": [
        "#MLP Multi-layer perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNDIZG-STuTQ"
      },
      "outputs": [],
      "source": [
        "# Set up the number of perceptron per each layer:\n",
        "p=4 # Layer 1\n",
        "q=4 # Layer 2\n",
        "\n",
        "# Set up the Learning rate\n",
        "eta =  1/623\n",
        "\n",
        "\n",
        "# 0: Random initialize the relevant data\n",
        "w1 = 2*np.random.rand(p , X_train.shape[1]) - 0.5 # Layer 1\n",
        "b1 = np.random.rand(p)\n",
        "\n",
        "w2 = 2*np.random.rand(q , p) - 0.5  # Layer 2\n",
        "b2 = np.random.rand(q)\n",
        "\n",
        "wOut = 2*np.random.rand(q) - 0.5  # Output Layer\n",
        "bOut = np.random.rand(1)\n",
        "\n",
        "mu = []\n",
        "vec_y = []\n",
        "\n",
        "# Start looping over the passengers, i.e. over I.\n",
        "\n",
        "for I in range(0, X_train.shape[0]): #loop in all the passengers:\n",
        "\n",
        "    # 1: input the data\n",
        "    x = X_train[I]\n",
        "\n",
        "\n",
        "    # 2: Start the algorithm\n",
        "\n",
        "    # 2.1: Feed forward\n",
        "    z1 = ReLU_act(np.dot(w1, x) + b1) # output layer 1\n",
        "    z2 = ReLU_act(np.dot(w2, z1) + b2) # output layer 2\n",
        "    y = sigmoid_act(np.dot(wOut, z2) + bOut) # Output of the Output layer\n",
        "\n",
        "    #2.2: Compute the output layer's error\n",
        "    delta_Out =  (y-Y_train[I]) * sigmoid_act(y, der=True)\n",
        "\n",
        "    #2.3: Backpropagate\n",
        "    delta_2 = delta_Out * wOut * ReLU_act(z2, der=True) # Second Layer Error\n",
        "    delta_1 = np.dot(delta_2, w2) * ReLU_act(z1, der=True) # First Layer Error\n",
        "\n",
        "    # 3: Gradient descent\n",
        "    wOut = wOut - eta*delta_Out*z2  # Outer Layer\n",
        "    bOut = bOut - eta*delta_Out\n",
        "\n",
        "    w2 = w2 - eta*np.kron(delta_2, z1).reshape(q,p) # Hidden Layer 2\n",
        "    b2 = b2 - eta*delta_2\n",
        "\n",
        "    w1 = w1 - eta*np.kron(delta_1, x).reshape(p, x.shape[0]) # Hidden Layer 1\n",
        "    b1 = b1 - eta*delta_1\n",
        "\n",
        "    # 4. Computation of the loss function\n",
        "    mu.append((1/2)*(y-Y_train[I])**2)\n",
        "    vec_y.append(y[0])\n",
        "\n",
        "\n",
        "# Plotting the Cost function for each training data\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(np.arange(0, X_train.shape[0]), mu, alpha=0.3, s=4, label='mu')\n",
        "plt.title('Loss for each training data point', fontsize=20)\n",
        "plt.xlabel('Training data', fontsize=16)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Plotting the average cost function over 10 training data\n",
        "pino = []\n",
        "for i in range(0, 9):\n",
        "    pippo = 0\n",
        "    for m in range(0, 59):\n",
        "        pippo+=vec_y[60*i+m]/60\n",
        "    pino.append(pippo)\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(np.arange(0, 9), pino, alpha=1, s=10, label='error')\n",
        "plt.title('Averege Loss by epoch', fontsize=20)\n",
        "plt.xlabel('Epoch', fontsize=16)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQN5G1YcTuTQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKwVCRpATuTR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqtySrhATuTR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CImF4DJpTuTR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZso2YZ8TuTR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOXlul11TuTR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJWMSYwmTuTR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DL3-2cDhTuTR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aahY35xHTuTR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-iyyresTuTR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv3fcoHuTuTS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gGZaWibTuTS",
        "outputId": "c1d5d03e-9678-45ad-c1d1-1ab1eaa51bf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.85      0.89        93\n",
            "           1       0.86      0.95      0.90        91\n",
            "\n",
            "    accuracy                           0.90       184\n",
            "   macro avg       0.90      0.90      0.90       184\n",
            "weighted avg       0.90      0.90      0.90       184\n",
            "\n",
            "[[79 14]\n",
            " [ 5 86]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "# 2. instantiate a logistic regression model\n",
        "logreg = LogisticRegression(random_state=1000, solver='saga',multi_class='ovr',C=2.0)\n",
        "# 3. train the model using X_train_dtm\n",
        "x=logreg.fit(X_train, y_train)\n",
        "# 4. make class predictions for X_test_dtm\n",
        "y_pred_class = logreg.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_class))\n",
        "print(confusion_matrix(y_test,y_pred_class))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d-LIzQ9TuTS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUhHHAuhTuTS",
        "outputId": "240bd199-d530-4b76-ec70-4373f11be6bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVC\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.85      0.89        93\n",
            "           1       0.86      0.95      0.90        91\n",
            "\n",
            "    accuracy                           0.90       184\n",
            "   macro avg       0.90      0.90      0.90       184\n",
            "weighted avg       0.90      0.90      0.90       184\n",
            "\n",
            "[[79 14]\n",
            " [ 5 86]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "print(\"SVC\")\n",
        "svm = SVC(kernel='sigmoid', C=1.0, random_state=2)\n",
        "svm.fit(X_train,y_train)\n",
        "y_pred=svm.predict(X_test)\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rjo1FICTuTS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSBB6HpMTuTS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxH55mcLTuTS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ei94OIUmTuTU"
      },
      "outputs": [],
      "source": [
        "# Splitting dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(rounded_predictions, target, test_size=0.20, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlco5Lr3TuTU",
        "outputId": "e02821f7-cde0-444a-911f-5268f583880f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ETC\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.85      0.84        73\n",
            "           1       0.90      0.88      0.89       111\n",
            "\n",
            "    accuracy                           0.87       184\n",
            "   macro avg       0.86      0.87      0.86       184\n",
            "weighted avg       0.87      0.87      0.87       184\n",
            "\n",
            "[[62 11]\n",
            " [13 98]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "print(\"ETC\")\n",
        "b = ExtraTreesClassifier(n_estimators=300, random_state=5, max_depth=20)\n",
        "b_pred = b.fit(X_train, y_train).predict(X_test)\n",
        "print(classification_report(y_test,b_pred))\n",
        "print(confusion_matrix(y_test,b_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xGZFnUMTuTU",
        "outputId": "2c6cc400-5159-4f02-c0c6-904ecc870aa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ADA\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.79      0.79        73\n",
            "           1       0.86      0.86      0.86       111\n",
            "\n",
            "    accuracy                           0.84       184\n",
            "   macro avg       0.83      0.83      0.83       184\n",
            "weighted avg       0.84      0.84      0.84       184\n",
            "\n",
            "[[58 15]\n",
            " [15 96]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "print(\"ADA\")\n",
        "xgb = AdaBoostClassifier(n_estimators=100, random_state=5)\n",
        "xgb_pred = xgb.fit(X_train, y_train).predict(X_test)\n",
        "print(classification_report(y_test,xgb_pred))\n",
        "print(confusion_matrix(y_test,xgb_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1CaTq7uTuTV",
        "outputId": "c8b175b4-b1b4-4b8e-b1de-b3665f998610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.85      0.83        73\n",
            "           1       0.90      0.87      0.89       111\n",
            "\n",
            "    accuracy                           0.86       184\n",
            "   macro avg       0.86      0.86      0.86       184\n",
            "weighted avg       0.87      0.86      0.86       184\n",
            "\n",
            "[[62 11]\n",
            " [14 97]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "r1 = LogisticRegression(random_state=1000, solver='saga',multi_class='ovr',C=2.0)\n",
        "r2 = SVC(kernel='sigmoid', C=1.0, random_state=2, probability=True)\n",
        "er = VotingClassifier([('lr', r1),('svc', r2)],voting=\"soft\")\n",
        "\n",
        "x=er.fit(X_train, y_train)\n",
        "\n",
        "y_pred_class = er.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_class))\n",
        "print(confusion_matrix(y_test,y_pred_class))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1JIQIMxTuTV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F08tq0GRTuTV",
        "outputId": "6ab4078a-0ca2-4a86-84d6-5744db8020e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.82      0.84        66\n",
            "           1       0.84      0.88      0.86        72\n",
            "\n",
            "    accuracy                           0.85       138\n",
            "   macro avg       0.85      0.85      0.85       138\n",
            "weighted avg       0.85      0.85      0.85       138\n",
            "\n",
            "[[54 12]\n",
            " [ 9 63]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "# 2. instantiate a logistic regression model\n",
        "logreg = LogisticRegression(random_state=1000, solver='saga',multi_class='ovr',C=2.0)\n",
        "# 3. train the model using X_train_dtm\n",
        "x=logreg.fit(X_train, y_train)\n",
        "# 4. make class predictions for X_test_dtm\n",
        "y_pred_class = logreg.predict(X_test)\n",
        "print(classification_report(y_test,y_pred_class))\n",
        "print(confusion_matrix(y_test,y_pred_class))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If-OSbFtTuTV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5OzL5ukTuTV",
        "outputId": "845cdbd8-5f20-4939-fa75-e7757920d91a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVC\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.82      0.83        66\n",
            "           1       0.84      0.86      0.85        72\n",
            "\n",
            "    accuracy                           0.84       138\n",
            "   macro avg       0.84      0.84      0.84       138\n",
            "weighted avg       0.84      0.84      0.84       138\n",
            "\n",
            "[[54 12]\n",
            " [10 62]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "print(\"SVC\")\n",
        "svm = SVC(kernel='sigmoid', C=2.0, random_state=2)\n",
        "svm.fit(X_train,y_train)\n",
        "y_pred=svm.predict(X_test)\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKaT7H-vTuTV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMklomeMTuTV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtOI8R2pTuTV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4nzlbb1TuTW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlSn8vchTuTW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtmqASKgTuTW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBIk7AT4TuTW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wV5C6cZTuTW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyeK69MaTuTW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiyEjhAoTuTW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAkFqesETuTX"
      },
      "outputs": [],
      "source": [
        "def nearest_on_circle(c, R, x):\n",
        "    cos_=(x2-c2)/euclidean_dist(x1,x2,c1,c2)\n",
        "    sin_=(x1-c1)/euclidean_dist(x1,x2,c1,c2)\n",
        "    #then extrpolate the center along this line to a distance equal to that of radius\n",
        "    #to obtain the nearest point\n",
        "    y1=c1+r*cos_\n",
        "    y2=c2+r*sin_\n",
        "    y=y1,y2\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bz6r4tixTuTX"
      },
      "outputs": [],
      "source": [
        "def euclidean_dist(x1,y1,x2,y2):\n",
        "    return math.sqrt((x1-x2)**2 +(y1-y2)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tMXFoQyTuTX"
      },
      "outputs": [],
      "source": [
        "def reflections_in_tunnel(w, h, alpha, n):\n",
        "    x=(n*w-h)/math.tan(alpha)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMCW_6GjTuTX",
        "outputId": "e51b71e7-59fd-4788-a8a0-53df4388c736"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.15611995216165922"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reflections_in_tunnel(2, 3, 30, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSYAE4_RTuTX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_pA63yITuTX"
      },
      "outputs": [],
      "source": [
        "def reflection_on_circle(c_x, R, alpha):\n",
        "    #formula to find Sin Beta\n",
        "    sinB=(c_x/R)*math.sin(alpha)\n",
        "    # Now L will be\n",
        "    L=c_x+(R*sinB)/(math.cos(alpha)*(1-2*math.sin(sinB)**2)-(2*math.sin(alpha)*math.sin(sinB))*(math.sqrt(1-math.sin(sinB)**2)))\n",
        "    return L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIsg8qVBTuTY"
      },
      "outputs": [],
      "source": [
        "B=[[1,0],[1,0],[1,0]]\n",
        "v=[1,2,2]\n",
        "B=np.array(B)\n",
        "v=np.array(v)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UY5vbjL-TuTY",
        "outputId": "7657bb2a-db5c-41db-80ae-e1a41d3b3eda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[3.42],\n",
              "       [1.55],\n",
              "       [3.65]])"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "x = np.array([[0, 0, 1],\n",
        "              [0, 1, 0],\n",
        "              [1, 0, 0]])\n",
        "y = ([[3.65], [1.55], [3.42]])\n",
        "x = np.array(x)\n",
        "scalars = np.linalg.solve(x, y)\n",
        "scalars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZMPoWMETuTY",
        "outputId": "8711c70a-a03a-49da-cafc-e749efba8dab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[3.42, 3.42, 2.42],\n",
              "       [1.55, 2.55, 1.55],\n",
              "       [2.65, 3.65, 3.65]])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from scipy.linalg import orth\n",
        "o=orth(x)\n",
        "v=scalars+o\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6QjC7mXTuTY"
      },
      "outputs": [],
      "source": [
        "def orthogonal_components(B, v):\n",
        "    B = np.array(B)\n",
        "    v = np.array(v)\n",
        "    v11 = np.linalg.solve(x, y)\n",
        "    from scipy.linalg import orth\n",
        "    vp=orth(x)\n",
        "    return v11,vp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EizqdOONTuTY",
        "outputId": "e92907ea-906f-432b-9145-e3c6ded67ade"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[3.42],\n",
              "        [1.55],\n",
              "        [3.65]]),\n",
              " array([[ 0.,  0., -1.],\n",
              "        [ 0.,  1.,  0.],\n",
              "        [-1.,  0.,  0.]]))"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "orthogonal_components(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDgt647ZTuTY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C49u6uS3TuTZ"
      },
      "outputs": [],
      "source": [
        "def marginal_x(P):\n",
        "    p=np.array(P)\n",
        "    from scipy.stats.contingency import margins\n",
        "    x, y = margins(p)\n",
        "    return x.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5vH3WaOTuTc",
        "outputId": "f9185408-2a34-4515-88bb-766c74f41d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.11 0.48 0.3  0.11]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "p = np.array([[0.01, 0.02, 0.04, 0.04],\n",
        "                [0.03, 0.24, 0.15, 0.06],\n",
        "                [0.04, 0.10, 0.08, 0.08],\n",
        "                [0.02, 0.04, 0.03, 0.02]\n",
        "            ])\n",
        "\n",
        "\n",
        "a=marginal_x(p)\n",
        "a=np.array(a)\n",
        "print(marginal_x(p))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1enSfKNTuTc"
      },
      "outputs": [],
      "source": [
        "def calc_Expectation(P):\n",
        "\t\tp=np.array(P)\n",
        "\t\tsum = 0\n",
        "\t\tfrom scipy.stats.contingency import margins\n",
        "\t\tx, y = margins(p)\n",
        "\t\ta=np.array(y.T)\n",
        "\t\tfor i in range(len(a)):\n",
        "\t\t\tsum=sum+ (a[i])\n",
        "\t\te=float(sum)\n",
        "\t\treturn e\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PB96DD4uTuTd"
      },
      "outputs": [],
      "source": [
        "def calc_Expectation(P):\n",
        "\t\tp=np.array(P)\n",
        "\t\tsum = 0\n",
        "\t\tfrom scipy.stats.contingency import margins\n",
        "\t\tx, y = margins(p)\n",
        "\t\ta=np.array(y.T)\n",
        "\t\ta=np.array(y.T)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPpmFT_0TuTd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhuVDFa9TuTd",
        "outputId": "41fd973b-4037-4d36-b2f5-422e057c0a01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "calc_Expectation(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5rcyOqRTuTd"
      },
      "outputs": [],
      "source": [
        "def calc_Expectation(P, n):\n",
        "\t\tprb = 1 / n\n",
        "\t\tsum = 0\n",
        "\t\tp=np.array(P)\n",
        "\t\tfrom scipy.stats.contingency import margins\n",
        "\t\tx, y = margins(p)\n",
        "\t\ta=np.array(x*y.T)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZSOcbqHTuTd",
        "outputId": "09615c0b-7825-4293-ea6f-1752ee7d81a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1015"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p = np.array([[0.01, 0.02, 0.04, 0.04],\n",
        "                [0.03, 0.24, 0.15, 0.06],\n",
        "                [0.04, 0.10, 0.08, 0.08],\n",
        "                [0.02, 0.04, 0.03, 0.02]\n",
        "            ])\n",
        "\n",
        "\n",
        "n=2\n",
        "calc_Expectation(p,n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ0TTRROTuTd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6QG49BITuTd",
        "outputId": "b8fd109a-7187-4613-e562-b6278702f8d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0.]]),\n",
              " array([3, 4, 4, 5, 6, 7]))"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def repeated_entries(x):\n",
        "    a=np.array(x.T)\n",
        "    N = len(x)\n",
        "    L=len(a)\n",
        "    S = np.zeros((N, L))\n",
        "    u = a\n",
        "    return S, u\n",
        "\n",
        "x=np.array([3,4,4,5,6,7])\n",
        "repeated_entries(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QBKanayTuTe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}